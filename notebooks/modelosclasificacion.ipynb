{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10086072,"sourceType":"datasetVersion","datasetId":6218629}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:33:39.699894Z","iopub.execute_input":"2024-12-03T14:33:39.700263Z","iopub.status.idle":"2024-12-03T14:33:52.767161Z","shell.execute_reply.started":"2024-12-03T14:33:39.700227Z","shell.execute_reply":"2024-12-03T14:33:52.765654Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0+cpu)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import make_pipeline\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:33:52.769929Z","iopub.execute_input":"2024-12-03T14:33:52.770969Z","iopub.status.idle":"2024-12-03T14:34:18.264850Z","shell.execute_reply.started":"2024-12-03T14:33:52.770905Z","shell.execute_reply":"2024-12-03T14:34:18.263757Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Cargar los datasets\nartista_df = pd.read_csv('/kaggle/input/datasetclasificador/DatasetClassifier-Artista.csv')\nconsulta_df = pd.read_csv('/kaggle/input/datasetclasificador/Dataset classifier-ConsultarInformacion.csv')\nplaylist_df = pd.read_csv('/kaggle/input/datasetclasificador/Dataset classifier-CrearPlaylist.csv')\n\n# Asignar etiquetas a cada dataset\nartista_df['label'] = 'Artista'\nconsulta_df['label'] = 'ConsultarInformacion'\nplaylist_df['label'] = 'CrearPlaylist'\n\n# Combinar datasets\ndata = pd.concat([artista_df, consulta_df, playlist_df], ignore_index=True)\ndata['tipo'] = data['tipo'] - 1\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:18.266335Z","iopub.execute_input":"2024-12-03T14:34:18.267646Z","iopub.status.idle":"2024-12-03T14:34:18.345644Z","shell.execute_reply.started":"2024-12-03T14:34:18.267589Z","shell.execute_reply":"2024-12-03T14:34:18.344607Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:18.348979Z","iopub.execute_input":"2024-12-03T14:34:18.350070Z","iopub.status.idle":"2024-12-03T14:34:18.367114Z","shell.execute_reply.started":"2024-12-03T14:34:18.350010Z","shell.execute_reply":"2024-12-03T14:34:18.365656Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               frase  tipo    label\n0             ¿Puedes recomendarme un artista nuevo?     0  Artista\n1  Necesito sugerencias de artistas similares a C...     0  Artista\n2      ¿Qué artista me recomendarías para relajarme?     0  Artista\n3      ¿Tienes alguna recomendación de artistas pop?     0  Artista\n4              Recomiéndame un buen artista de jazz.     0  Artista","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frase</th>\n      <th>tipo</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>¿Puedes recomendarme un artista nuevo?</td>\n      <td>0</td>\n      <td>Artista</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Necesito sugerencias de artistas similares a C...</td>\n      <td>0</td>\n      <td>Artista</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>¿Qué artista me recomendarías para relajarme?</td>\n      <td>0</td>\n      <td>Artista</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>¿Tienes alguna recomendación de artistas pop?</td>\n      <td>0</td>\n      <td>Artista</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Recomiéndame un buen artista de jazz.</td>\n      <td>0</td>\n      <td>Artista</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:18.368950Z","iopub.execute_input":"2024-12-03T14:34:18.369489Z","iopub.status.idle":"2024-12-03T14:34:18.377785Z","shell.execute_reply.started":"2024-12-03T14:34:18.369430Z","shell.execute_reply":"2024-12-03T14:34:18.376532Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(3020, 3)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:18.379228Z","iopub.execute_input":"2024-12-03T14:34:18.379591Z","iopub.status.idle":"2024-12-03T14:34:18.396069Z","shell.execute_reply.started":"2024-12-03T14:34:18.379536Z","shell.execute_reply":"2024-12-03T14:34:18.394820Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  frase  tipo          label\n3015  Quiero canciones modernas y energéticas para h...     2  CrearPlaylist\n3016  Busco música que combine con un ambiente juven...     2  CrearPlaylist\n3017  Quiero una lista de canciones de pop y indie p...     2  CrearPlaylist\n3018  Necesito música optimista y alegre para animar...     2  CrearPlaylist\n3019  Quiero una playlist fresca y estilosa para dar...     2  CrearPlaylist","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frase</th>\n      <th>tipo</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3015</th>\n      <td>Quiero canciones modernas y energéticas para h...</td>\n      <td>2</td>\n      <td>CrearPlaylist</td>\n    </tr>\n    <tr>\n      <th>3016</th>\n      <td>Busco música que combine con un ambiente juven...</td>\n      <td>2</td>\n      <td>CrearPlaylist</td>\n    </tr>\n    <tr>\n      <th>3017</th>\n      <td>Quiero una lista de canciones de pop y indie p...</td>\n      <td>2</td>\n      <td>CrearPlaylist</td>\n    </tr>\n    <tr>\n      <th>3018</th>\n      <td>Necesito música optimista y alegre para animar...</td>\n      <td>2</td>\n      <td>CrearPlaylist</td>\n    </tr>\n    <tr>\n      <th>3019</th>\n      <td>Quiero una playlist fresca y estilosa para dar...</td>\n      <td>2</td>\n      <td>CrearPlaylist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"X = data['frase']\ny = data['tipo']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\ntfidf = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf.fit_transform(X_train)\nX_test_tfidf = tfidf.transform(X_test)\n\nmodels = {\n    'SVM': SVC(kernel='linear', probability=True),\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42)\n}\n\nfor name, model in models.items():\n    model.fit(X_train_tfidf, y_train)\n    y_pred = model.predict(X_test_tfidf)\n    print(f\"Resultados para {name}:\")\n    print(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:18.397378Z","iopub.execute_input":"2024-12-03T14:34:18.397804Z","iopub.status.idle":"2024-12-03T14:34:20.785638Z","shell.execute_reply.started":"2024-12-03T14:34:18.397749Z","shell.execute_reply":"2024-12-03T14:34:20.784211Z"}},"outputs":[{"name":"stdout","text":"Resultados para SVM:\n              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99       200\n           1       1.00      1.00      1.00       203\n           2       0.98      1.00      0.99       201\n\n    accuracy                           0.99       604\n   macro avg       0.99      0.99      0.99       604\nweighted avg       0.99      0.99      0.99       604\n\nResultados para Random Forest:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99       200\n           1       0.99      1.00      0.99       203\n           2       0.99      0.99      0.99       201\n\n    accuracy                           0.99       604\n   macro avg       0.99      0.99      0.99       604\nweighted avg       0.99      0.99      0.99       604\n\nResultados para Logistic Regression:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99       200\n           1       0.97      1.00      0.99       203\n           2       0.99      0.97      0.98       201\n\n    accuracy                           0.99       604\n   macro avg       0.99      0.99      0.99       604\nweighted avg       0.99      0.99      0.99       604\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model_name = 'all-MiniLM-L6-v2'\nembedder = SentenceTransformer(model_name)\n\nX_embeddings = embedder.encode(X.tolist(), show_progress_bar=True)\nX_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_embeddings, y, test_size=0.2, random_state=42, stratify=y)\n\nclf = SVC(kernel='linear')\nclf.fit(X_train_emb, y_train_emb)\ny_pred_emb = clf.predict(X_test_emb)\n\nprint(\"Resultados con Sentence Transformers:\")\nprint(classification_report(y_test_emb, y_pred_emb))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:20.787385Z","iopub.execute_input":"2024-12-03T14:34:20.787932Z","iopub.status.idle":"2024-12-03T14:34:43.783013Z","shell.execute_reply.started":"2024-12-03T14:34:20.787875Z","shell.execute_reply":"2024-12-03T14:34:43.781700Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2924cf10fc024b5a968d37558fc1a796"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c30205f3b8f493286d85ac5df118ea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54c8efa84af2433580fce94b511394f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d0d4d25ee7400fb532607c6f1063ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5399c1099b4484ca3851a25a3ae1d20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"828e4dadfbed4edb8da81062fb77101f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca6dcd237794cf59509aa8fd3ca9dbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4b745e011a46129843bcb782c6fca3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b405bd050f1640879830aab786915bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ac6a6392f4841029a8243aacc8e5fdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f6939c0436477e85957c0e77565ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/95 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ca076f90054e4f96b8fb46eb0635d4"}},"metadata":{}},{"name":"stdout","text":"Resultados con Sentence Transformers:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99       200\n           1       0.97      1.00      0.99       203\n           2       0.99      0.97      0.98       201\n\n    accuracy                           0.99       604\n   macro avg       0.99      0.99      0.99       604\nweighted avg       0.99      0.99      0.99       604\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer.encode_plus(\n            text,\n            max_length=self.max_len,\n            add_special_tokens=True,\n            truncation=True,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors=\"pt\"\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:43.785113Z","iopub.execute_input":"2024-12-03T14:34:43.785586Z","iopub.status.idle":"2024-12-03T14:34:43.792768Z","shell.execute_reply.started":"2024-12-03T14:34:43.785534Z","shell.execute_reply":"2024-12-03T14:34:43.791646Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"X_train = X_train.reset_index(drop=True)\ny_train = pd.Series(y_train).reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_test = pd.Series(y_test).reset_index(drop=True)\n\nprint(f\"Longitud de X_train: {len(X_train)}\")\nprint(f\"Longitud de y_train: {len(y_train)}\")\nprint(f\"Longitud de X_train: {len(X_test)}\")\nprint(f\"Longitud de y_train: {len(y_test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:43.796779Z","iopub.execute_input":"2024-12-03T14:34:43.797211Z","iopub.status.idle":"2024-12-03T14:34:43.840273Z","shell.execute_reply.started":"2024-12-03T14:34:43.797164Z","shell.execute_reply":"2024-12-03T14:34:43.839153Z"}},"outputs":[{"name":"stdout","text":"Longitud de X_train: 2416\nLongitud de y_train: 2416\nLongitud de X_train: 604\nLongitud de y_train: 604\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nnum_classes = data['tipo'].nunique()\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n\ntrain_dataset = TextDataset(\n    X_train,\n    y_train,\n    tokenizer,\n    max_len=128\n)\n\ntest_dataset = TextDataset(\n    X_test,\n    y_test,\n    tokenizer,\n    max_len=128\n)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\noptimizer = Adam(model.parameters(), lr=2e-5)\n\nfor epoch in range(3):\n    model.train()\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:34:43.841562Z","iopub.execute_input":"2024-12-03T14:34:43.841899Z","iopub.status.idle":"2024-12-03T15:52:21.130669Z","shell.execute_reply.started":"2024-12-03T14:34:43.841867Z","shell.execute_reply":"2024-12-03T15:52:21.129526Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11cacebf3c741c9aeb0fad1f553804a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f247f80871cf45a9870db2fe1f555016"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca041214b0a94291bf38a98a021e8483"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4af247ed9944141bdc1b0d0a27380de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49350a3470e443284e202f589bbf72c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 0: 100%|██████████| 151/151 [25:55<00:00, 10.30s/it, loss=0.0276]\nEpoch 1: 100%|██████████| 151/151 [25:56<00:00, 10.31s/it, loss=0.0191] \nEpoch 2: 100%|██████████| 151/151 [25:42<00:00, 10.21s/it, loss=0.00288]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"data['label'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:52:21.132026Z","iopub.execute_input":"2024-12-03T15:52:21.132373Z","iopub.status.idle":"2024-12-03T15:52:21.146502Z","shell.execute_reply.started":"2024-12-03T15:52:21.132339Z","shell.execute_reply":"2024-12-03T15:52:21.145210Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['Artista', 'ConsultarInformacion', 'CrearPlaylist'], dtype=object)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Evaluación del modelo\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, axis=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nprint(\"Resultados con BERT:\")\nprint(classification_report(all_labels, all_preds, target_names=data['label'].unique()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:54:25.369449Z","iopub.execute_input":"2024-12-03T15:54:25.369799Z","iopub.status.idle":"2024-12-03T15:56:22.301207Z","shell.execute_reply.started":"2024-12-03T15:54:25.369762Z","shell.execute_reply":"2024-12-03T15:56:22.300025Z"}},"outputs":[{"name":"stdout","text":"Resultados con BERT:\n                      precision    recall  f1-score   support\n\n             Artista       1.00      0.99      0.99       200\nConsultarInformacion       1.00      0.99      1.00       203\n       CrearPlaylist       0.98      1.00      0.99       201\n\n            accuracy                           0.99       604\n           macro avg       0.99      0.99      0.99       604\n        weighted avg       0.99      0.99      0.99       604\n\n","output_type":"stream"}],"execution_count":14}]}